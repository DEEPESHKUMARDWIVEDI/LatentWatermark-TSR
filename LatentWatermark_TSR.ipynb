{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f5af7b",
   "metadata": {},
   "source": [
    "### Prepare GTSRB train and test DataLoaders for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e24e42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils.gtsrb_dataset import GTSRBDataset\n",
    "from models.tsr_cnn import TSRNet\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm \n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Datasets & loaders\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomAffine(0, translate=(0.1,0.1)),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = GTSRBDataset(csv_file=\"./data/Train.csv\", root_dir=\"./data/\", transform=transform_train)\n",
    "test_dataset  = GTSRBDataset(csv_file=\"./data/Test.csv\",  root_dir=\"./data/\", transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443aa4ca",
   "metadata": {},
   "source": [
    "### Train CNN-based traffic sign recognition model on the GTSRB dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f203cff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 613/613 [00:13<00:00, 45.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] Loss: 2.7513 | Train Acc: 24.63%\n",
      " Test Accuracy: 36.41%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 613/613 [00:12<00:00, 48.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30] Loss: 1.9111 | Train Acc: 43.88%\n",
      " Test Accuracy: 43.57%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 613/613 [00:11<00:00, 51.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30] Loss: 1.5100 | Train Acc: 55.40%\n",
      " Test Accuracy: 51.20%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 613/613 [00:12<00:00, 50.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30] Loss: 1.2257 | Train Acc: 64.59%\n",
      " Test Accuracy: 60.41%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 613/613 [00:12<00:00, 49.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30] Loss: 0.9960 | Train Acc: 72.21%\n",
      " Test Accuracy: 68.76%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 613/613 [00:11<00:00, 53.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30] Loss: 0.8193 | Train Acc: 77.55%\n",
      " Test Accuracy: 73.29%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 613/613 [00:12<00:00, 49.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30] Loss: 0.6888 | Train Acc: 81.59%\n",
      " Test Accuracy: 70.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 613/613 [00:11<00:00, 52.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30] Loss: 0.5820 | Train Acc: 84.74%\n",
      " Test Accuracy: 76.17%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 613/613 [00:13<00:00, 44.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30] Loss: 0.4966 | Train Acc: 87.44%\n",
      " Test Accuracy: 78.23%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 613/613 [00:12<00:00, 48.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30] Loss: 0.4353 | Train Acc: 88.90%\n",
      " Test Accuracy: 80.95%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 613/613 [00:13<00:00, 46.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30] Loss: 0.3813 | Train Acc: 90.57%\n",
      " Test Accuracy: 84.13%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 613/613 [00:11<00:00, 54.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30] Loss: 0.3359 | Train Acc: 91.82%\n",
      " Test Accuracy: 84.60%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 613/613 [00:13<00:00, 46.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30] Loss: 0.3016 | Train Acc: 92.55%\n",
      " Test Accuracy: 86.07%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 613/613 [00:11<00:00, 53.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30] Loss: 0.2754 | Train Acc: 93.34%\n",
      " Test Accuracy: 85.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 613/613 [00:13<00:00, 43.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30] Loss: 0.2473 | Train Acc: 94.03%\n",
      " Test Accuracy: 83.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 613/613 [00:12<00:00, 49.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30] Loss: 0.2250 | Train Acc: 94.63%\n",
      " Test Accuracy: 84.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 613/613 [00:13<00:00, 44.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30] Loss: 0.2041 | Train Acc: 95.30%\n",
      " Test Accuracy: 87.55%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 613/613 [00:13<00:00, 46.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30] Loss: 0.1905 | Train Acc: 95.54%\n",
      " Test Accuracy: 88.51%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 613/613 [00:15<00:00, 40.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30] Loss: 0.1729 | Train Acc: 96.01%\n",
      " Test Accuracy: 88.56%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 613/613 [00:12<00:00, 48.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30] Loss: 0.1610 | Train Acc: 96.22%\n",
      " Test Accuracy: 90.47%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 613/613 [00:13<00:00, 45.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30] Loss: 0.1483 | Train Acc: 96.52%\n",
      " Test Accuracy: 90.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 613/613 [00:12<00:00, 47.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30] Loss: 0.1359 | Train Acc: 96.94%\n",
      " Test Accuracy: 91.27%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 613/613 [00:13<00:00, 46.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30] Loss: 0.1304 | Train Acc: 96.92%\n",
      " Test Accuracy: 90.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 613/613 [00:12<00:00, 50.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30] Loss: 0.1203 | Train Acc: 97.26%\n",
      " Test Accuracy: 91.47%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 613/613 [00:14<00:00, 43.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30] Loss: 0.1203 | Train Acc: 97.22%\n",
      " Test Accuracy: 90.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 613/613 [00:11<00:00, 51.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30] Loss: 0.1032 | Train Acc: 97.71%\n",
      " Test Accuracy: 91.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 613/613 [00:13<00:00, 44.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30] Loss: 0.1031 | Train Acc: 97.64%\n",
      " Test Accuracy: 92.08%\n",
      "Saved checkpoint: results/checkpoints/tsr/tsr_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 613/613 [00:11<00:00, 52.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30] Loss: 0.0999 | Train Acc: 97.73%\n",
      " Test Accuracy: 90.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 613/613 [00:13<00:00, 44.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30] Loss: 0.0895 | Train Acc: 98.01%\n",
      " Test Accuracy: 91.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 613/613 [00:12<00:00, 49.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30] Loss: 0.0838 | Train Acc: 98.20%\n",
      " Test Accuracy: 91.96%\n",
      "Training complete. Best accuracy: 92.08%\n"
     ]
    }
   ],
   "source": [
    "from utils.train_tsr import train_tsr\n",
    "from models.tsr_cnn import TSRNet\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from utils.gtsrb_dataset import GTSRBDataset\n",
    "\n",
    "# Model\n",
    "model = TSRNet(num_classes=43).to(device)\n",
    "\n",
    "# Train\n",
    "model, best_acc = train_tsr(model, train_loader, test_loader, device, num_epochs=30,ckpt_dir=\"results/checkpoints/tsr\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4001c4",
   "metadata": {},
   "source": [
    "### Loads a trained TSRNet, evaluates clean accuracy and robustness to FGSM/PGD and adversarial patch attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d18ae8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy: 92.08234362628662\n",
      "FGSM Adv Acc: 5.65%, ASR: 93.86%\n",
      "PGD Adv Acc: 0.53%, ASR: 99.42%\n",
      "[Patch train] Epoch 1/20, loss: -5.8076\n",
      "[Patch train] Epoch 10/20, loss: -7.6828\n",
      "[Patch train] Epoch 20/20, loss: -7.6958\n",
      "Patch attack eval: {'clean_acc': 92.08234362628662, 'adv_acc': 19.849564528899446, 'asr': 78.82201203783319}\n"
     ]
    }
   ],
   "source": [
    "from models.tsr_cnn import TSRNet\n",
    "from utils.attack_eval import evaluate_clean, evaluate_fgsm, evaluate_pgd, evaluate_patch\n",
    "from utils.attacks import train_adversarial_patch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Datasets & loaders\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "train_dataset = GTSRBDataset(csv_file=\"./data/Train.csv\", root_dir=\"./data/\", transform=transform)\n",
    "test_dataset  = GTSRBDataset(csv_file=\"./data/Test.csv\",  root_dir=\"./data/\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "# Load TSR model\n",
    "model = TSRNet(num_classes=43).to(device)\n",
    "ckpt = torch.load(\"results/checkpoints/tsr/tsr_best_model.pth\", map_location=device)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Evaluate clean accuracy\n",
    "clean_acc = evaluate_clean(model, test_loader, device)\n",
    "print(\"Clean Accuracy:\", clean_acc)\n",
    "\n",
    "# FGSM\n",
    "eps = 0.03\n",
    "adv_acc, asr = evaluate_fgsm(model, test_loader, device, eps)\n",
    "print(f\"FGSM Adv Acc: {adv_acc:.2f}%, ASR: {asr:.2f}%\")\n",
    "\n",
    "# PGD\n",
    "adv_acc, asr = evaluate_pgd(model, test_loader, device, eps, alpha=0.007, iters=20)\n",
    "print(f\"PGD Adv Acc: {adv_acc:.2f}%, ASR: {asr:.2f}%\")\n",
    "\n",
    "# Train and evaluate patch attack\n",
    "patch = train_adversarial_patch(model, train_loader, device, num_epochs=20, patch_size=0.18, lr=0.05)\n",
    "res = evaluate_patch(model, test_loader, patch, device, patch_size=0.18)\n",
    "print(\"Patch attack eval:\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be51d1",
   "metadata": {},
   "source": [
    "### Trains an Autoencoder on GTSRB data, evaluates reconstruction loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b768ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1/20: 100%|██████████| 613/613 [00:13<00:00, 46.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/20] Train Loss: 0.055553 | Test Loss: 0.026782\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2/20: 100%|██████████| 613/613 [00:13<00:00, 46.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/20] Train Loss: 0.023849 | Test Loss: 0.019219\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3/20: 100%|██████████| 613/613 [00:12<00:00, 47.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/20] Train Loss: 0.017851 | Test Loss: 0.015518\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4/20: 100%|██████████| 613/613 [00:12<00:00, 50.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/20] Train Loss: 0.014542 | Test Loss: 0.013602\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5/20: 100%|██████████| 613/613 [00:13<00:00, 46.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/20] Train Loss: 0.012856 | Test Loss: 0.012679\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 6/20: 100%|██████████| 613/613 [00:11<00:00, 54.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/20] Train Loss: 0.011955 | Test Loss: 0.012050\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 7/20: 100%|██████████| 613/613 [00:11<00:00, 51.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/20] Train Loss: 0.011296 | Test Loss: 0.011095\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 8/20: 100%|██████████| 613/613 [00:12<00:00, 51.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/20] Train Loss: 0.010640 | Test Loss: 0.010687\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 9/20: 100%|██████████| 613/613 [00:11<00:00, 51.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/20] Train Loss: 0.010437 | Test Loss: 0.010601\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 10/20: 100%|██████████| 613/613 [00:12<00:00, 48.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/20] Train Loss: 0.010071 | Test Loss: 0.010828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 11/20: 100%|██████████| 613/613 [00:13<00:00, 44.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/20] Train Loss: 0.009786 | Test Loss: 0.010326\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 12/20: 100%|██████████| 613/613 [00:11<00:00, 52.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/20] Train Loss: 0.009662 | Test Loss: 0.009927\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 13/20: 100%|██████████| 613/613 [00:13<00:00, 46.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/20] Train Loss: 0.009345 | Test Loss: 0.010218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 14/20: 100%|██████████| 613/613 [00:11<00:00, 54.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/20] Train Loss: 0.009244 | Test Loss: 0.009842\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 15/20: 100%|██████████| 613/613 [00:12<00:00, 48.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/20] Train Loss: 0.009179 | Test Loss: 0.010237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 16/20: 100%|██████████| 613/613 [00:14<00:00, 43.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/20] Train Loss: 0.008953 | Test Loss: 0.009647\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 17/20: 100%|██████████| 613/613 [00:12<00:00, 48.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/20] Train Loss: 0.008730 | Test Loss: 0.009506\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 18/20: 100%|██████████| 613/613 [00:12<00:00, 47.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/20] Train Loss: 0.008800 | Test Loss: 0.009706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 19/20: 100%|██████████| 613/613 [00:12<00:00, 50.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/20] Train Loss: 0.008624 | Test Loss: 0.010038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 20/20: 100%|██████████| 613/613 [00:14<00:00, 43.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/20] Train Loss: 0.008554 | Test Loss: 0.009347\n",
      "✅ Saved best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n",
      "Training finished. Best test loss: 0.009346777854173172\n",
      "Best checkpoint: results/checkpoints/autoencoder/autoencoder_best.pth\n"
     ]
    }
   ],
   "source": [
    "from utils.train_autoencoder import train_autoencoder\n",
    "from models.autoencoder import Autoencoder, load_checkpoint\n",
    "from utils.visualization import save_sample  # optional\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Cell: train\n",
    "model, best_loss, best_ckpt = train_autoencoder(\n",
    "    train_loader, test_loader, device,\n",
    "    latent_dim=128, num_epochs=20, lr=1e-3, ckpt_dir=\"results/checkpoints/autoencoder\"\n",
    ")\n",
    "print(\"Best checkpoint:\", best_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663874eb",
   "metadata": {},
   "source": [
    "### Train UNetWatermark + LatentDecoder to embed/recover latent features from images using pretrained Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a360f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unet Epoch 1/10: 100%|██████████| 613/613 [02:56<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Perceptual Loss: 28.817916\n",
      " Saved best UNet checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unet Epoch 2/10: 100%|██████████| 613/613 [02:57<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Perceptual Loss: 7.426892\n",
      " Saved best UNet checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unet Epoch 3/10: 100%|██████████| 613/613 [02:56<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Perceptual Loss: 3.893203\n",
      " Saved best UNet checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unet Epoch 4/10: 100%|██████████| 613/613 [03:09<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Perceptual Loss: 2.563822\n",
      " Saved best UNet checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unet Epoch 5/10: 100%|██████████| 613/613 [04:28<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Perceptual Loss: 1.893859\n",
      " Saved best UNet checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unet Epoch 6/10: 100%|██████████| 613/613 [02:56<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Perceptual Loss: 1.590430\n",
      " Saved best UNet checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unet Epoch 7/10:  30%|███       | 184/613 [00:53<02:05,  3.42it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/Train/10/00010_00051_00005.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_unet_watermark\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_unet_watermark\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgtsrb_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GTSRBDataset\n\u001b[0;32m----> 6\u001b[0m unet, best_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_unet_watermark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautoencoder_ckpt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresults/checkpoints/autoencoder/autoencoder_best.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_watermarked_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresults/watermarked\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresults/checkpoints/unet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished. Best perceptual loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_loss)\n",
      "File \u001b[0;32m/data/deepesh/LatentWatermark-TSR/utils/train_unet_watermark.py:50\u001b[0m, in \u001b[0;36mtrain_unet_watermark\u001b[0;34m(train_loader, device, autoencoder_ckpt, latent_dim, num_epochs, lr, save_watermarked_dir, ckpt_dir)\u001b[0m\n\u001b[1;32m     47\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     48\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgs, _ \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnet Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     51\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/data/deepesh/LatentWatermark-TSR/utils/gtsrb_dataset.py:74\u001b[0m, in \u001b[0;36mGTSRBDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     73\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 74\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     75\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m6\u001b[39m])  \u001b[38;5;66;03m# ClassId column\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/PIL/Image.py:3465\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3462\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fp)\n\u001b[1;32m   3464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3465\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3466\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3467\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/Train/10/00010_00051_00005.png'"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.train_unet_watermark import train_unet_watermark\n",
    "from utils.gtsrb_dataset import GTSRBDataset\n",
    "\n",
    "unet, best_loss = train_unet_watermark(\n",
    "    train_loader, device,\n",
    "    autoencoder_ckpt=\"results/checkpoints/autoencoder/autoencoder_best.pth\",\n",
    "    latent_dim=128,\n",
    "    num_epochs=10,\n",
    "    lr=1e-4,\n",
    "    save_watermarked_dir=\"results/watermarked\",\n",
    "    ckpt_dir=\"results/checkpoints/unet\"\n",
    ")\n",
    "print(\"Finished. Best perceptual loss:\", best_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819c676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/198 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;66;03m# PSNR & SSIM\u001b[39;00m\n\u001b[1;32m     79\u001b[0m         psnr_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m psnr(imgs, recon)\n\u001b[0;32m---> 80\u001b[0m         ssim_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mssim_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m         count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# --- Results ---\u001b[39;00m\n",
      "File \u001b[0;32m/data/deepesh/LatentWatermark-TSR/utils/metrics.py:31\u001b[0m, in \u001b[0;36mssim_batch\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     29\u001b[0m         a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(x[i], \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     30\u001b[0m         b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(y[i], \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m         res\u001b[38;5;241m.\u001b[39mappend(\u001b[43mssim\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultichannel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(res))\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skimage/metrics/_structural_similarity.py:186\u001b[0m, in \u001b[0;36mstructural_similarity\u001b[0;34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m         win_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m  \u001b[38;5;66;03m# backwards compatibility\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many((np\u001b[38;5;241m.\u001b[39masarray(im1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m-\u001b[39m win_size) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwin_size exceeds image extent. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEither ensure that your images are \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat least 7x7; or pass win_size explicitly \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min the function call, with an odd value \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mless than or equal to the smaller side of your \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages. If your images are multichannel \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(with color channels), set channel_axis to \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe axis number corresponding to the channels.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    195\u001b[0m     )\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (win_size \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWindow size must be odd.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels."
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Models & Utils\n",
    "from models.tsr_cnn import TSRNet\n",
    "from models.autoencoder import Autoencoder, load_checkpoint\n",
    "from models.unet_watermark import UNetWatermark\n",
    "from models.latent_decoder import LatentDecoder\n",
    "from utils.screen_noise import ScreenNoiseLayer\n",
    "from utils.gtsrb_dataset import GTSRBDataset\n",
    "from utils.metrics import psnr, ssim_batch\n",
    "\n",
    "\n",
    "# --- Load trained models ---\n",
    "latent_dim = 128\n",
    "tsr_model = TSRNet(num_classes=43).to(device)\n",
    "ckpt = torch.load(\"results/checkpoints/tsr/tsr_best_model.pth\", map_location=device)\n",
    "state_dict = ckpt['model_state_dict']\n",
    "\n",
    "# Filter out keys with size mismatch\n",
    "model_state_dict = tsr_model.state_dict()\n",
    "filtered_dict = {k: v for k, v in state_dict.items() if k in model_state_dict and v.size() == model_state_dict[k].size()}\n",
    "\n",
    "# Load filtered weights\n",
    "model_state_dict.update(filtered_dict)\n",
    "tsr_model.load_state_dict(model_state_dict)\n",
    "\n",
    "\n",
    "tsr_model.eval()\n",
    "\n",
    "autoencoder = Autoencoder(latent_dim=latent_dim).to(device)\n",
    "load_checkpoint(autoencoder, None, \"results/checkpoints/autoencoder/autoencoder_best.pth\", map_location=device)\n",
    "autoencoder.eval()\n",
    "\n",
    "unet = UNetWatermark(latent_dim=latent_dim).to(device)\n",
    "latent_decoder = LatentDecoder(latent_dim=latent_dim).to(device)\n",
    "screen_noise = ScreenNoiseLayer(noise_std=0.05).to(device)\n",
    "\n",
    "# # --- Dataset ---\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((32, 32)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "# ])\n",
    "# test_dataset = GTSRBDataset(csv_file=\"./data/Test.csv\", root_dir=\"./data/\", transform=transform)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# --- Evaluation ---\n",
    "correct, total = 0, 0\n",
    "psnr_total, ssim_total, count = 0.0, 0.0, 0\n",
    "\n",
    "for imgs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "    imgs, labels = imgs.to(device), labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        # Encode latent\n",
    "        z, _ = autoencoder(imgs)\n",
    "        \n",
    "        # Embed latent in image via UNet\n",
    "        Iw = unet(imgs, z)\n",
    "        \n",
    "        # Add screen noise\n",
    "        Iw_noisy = screen_noise(Iw)\n",
    "        \n",
    "        # Recover latent from noisy image\n",
    "        z_pred = latent_decoder(Iw_noisy)\n",
    "        \n",
    "        # Reconstruct image\n",
    "        recon = autoencoder.decoder(z_pred)\n",
    "        \n",
    "        # Evaluate TSR accuracy\n",
    "        outputs = tsr_model(recon)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # PSNR & SSIM\n",
    "        psnr_total += psnr(imgs, recon)\n",
    "        # ssim_total += ssim_batch(imgs, recon)\n",
    "        count += 1\n",
    "\n",
    "# --- Results ---\n",
    "acc = 100 * correct / total\n",
    "avg_psnr = psnr_total / count\n",
    "avg_ssim = ssim_total / count\n",
    "\n",
    "print(f\"TSR Accuracy on reconstructed images: {acc:.2f}%\")\n",
    "print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "print(f\"Average SSIM: {avg_ssim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a31bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save some sample reconstructions ---\n",
    "sample_imgs, _ = next(iter(test_loader))\n",
    "sample_imgs = sample_imgs[:8].to(device)\n",
    "with torch.no_grad():\n",
    "    z, _ = autoencoder(sample_imgs)\n",
    "    Iw = unet(sample_imgs, z)\n",
    "    Iw_noisy = screen_noise(Iw)\n",
    "    z_pred = latent_decoder(Iw_noisy)\n",
    "    recon = autoencoder.decoder(z_pred)\n",
    "save_image(torch.cat([(sample_imgs+1)/2, (recon+1)/2], dim=0), \"results/reconstruction_samples.png\", nrow=8)\n",
    "print(\"Saved reconstruction samples to results/reconstruction_samples.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latenttsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
